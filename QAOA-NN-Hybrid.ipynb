{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QAOA NN Hybrid\n",
    "\n",
    "In this Notebook we describe the QAOA+NN architecture implementation in Python. The packages needed are the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pennylane packages (for the quantum circuit)\n",
    "import pennylane as qml\n",
    "\n",
    "# TensorFlow packages (for optimizing the quantum circuit)\n",
    "import tensorflow as tf\n",
    "\n",
    "# Torch packages (for the neural network)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# Other packages\n",
    "import networkx as nx\n",
    "import tqdm.notebook as tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph definition \n",
    "For the graph definition we use the package `networkx`, but any other possible option given as a closed form is valid. However, some changes should be done on the rest of the code depending on the particular election."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just as an example, we generate a d-regular graph\n",
    "\n",
    "def dregular_graph(n,d,mu,sigma):\n",
    "    \"\"\"\n",
    "        n --> number of qubits\n",
    "        d --> number of edges connected to one node (n x d must be an even number)\n",
    "    \"\"\"\n",
    "    G= nx.generators.random_graphs.random_regular_graph(d,n)\n",
    "    for e in list(G.edges):\n",
    "        G[e[0]][e[1]][\"weight\"] = round(random.gauss(mu,sigma),2)\n",
    "    return G\n",
    "\n",
    "G = dregular_graph(5,4,0,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network definition\n",
    "\n",
    "Here we define our neural network together with its corresponding cost function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(len(G.nodes), 2*len(G.nodes), False)\n",
    "        #self.bn1 = nn.BatchNorm1d(len(G.nodes))\n",
    "        self.fc2 = nn.Linear(2*len(G.nodes), len(G.nodes), False)\n",
    "        #self.bn1 = nn.BatchNorm1d(32)\n",
    "        #self.fc3 = nn.Linear(2*len(G.nodes), len(G.nodes), False)\n",
    "        nn.init.eye_(self.fc1.weight)\n",
    "        nn.init.eye_(self.fc2.weight)\n",
    "        #nn.init.eye_(self.fc3.weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        #x = F.tanh(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MaxCut_NN(G,x):\n",
    "    adj = adjacency_matrix(G)\n",
    "    return 0.5*torch.matmul(x,torch.mv(adj,x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QAOA definition\n",
    "\n",
    "In this part of the code, we will define the QAOA gates, the QAOA circuit and the cost funtions employed for the minimization. Several notes about the quantum circuit:\n",
    "\n",
    "- It's a quantum simulator, so the circuit will deliver a tensor with the exact probability distributions of each possible bitstring. These exact probabilities will be used ONLY for the circuit optimization, meaning that the Neural Network needs another circuit (defined below) for obtaining a given number of samples. This minimzation for the circuit is only efficient for the circuit minimization, as we can't reach a very big number of qubits with a classical computer. For experimental implementations, the minimzation should be performed in a similar way as the NN does.\n",
    "- In this implementation, we compute the circuit gradients via backpropagation instead of using parameter shift. From a computational point of view, this seems to be faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost gate\n",
    "def U_C(gamma):\n",
    "    for e in list(G.edges):\n",
    "        wire1 = int(e[0])\n",
    "        wire2 = int(e[1])\n",
    "        qml.CNOT(wires=[wire1, wire2])\n",
    "        qml.RZ(G[wire1][wire2][\"weight\"]*gamma, wires=wire2)\n",
    "        qml.CNOT(wires=[wire1, wire2])\n",
    "\n",
    "# Mixer gate\n",
    "def U_M(gamma):\n",
    "    for n in list(G.nodes):\n",
    "        qml.RX(gamma, wires = n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the depth the circuit depth\n",
    "p = 1\n",
    "\n",
    "# Definition of the circuit together with the device\n",
    "dev = qml.device('default.qubit.tf', wires = len(G.nodes))\n",
    "@qml.qnode(dev, interface = \"tf\", diff_method = \"backprop\")\n",
    "def circuit(gamma, beta, **kwargs):\n",
    "    for i in range(len(G.nodes)):\n",
    "        qml.Hadamard(wires = i)\n",
    "    for j in range(p):\n",
    "        U_C(gamma[j])\n",
    "        U_M(beta[j])\n",
    "    return qml.probs(wires = list(range(len(G.nodes))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost funtion and other functions needed for the energy computation\n",
    "\n",
    "def string_to_tens(x):\n",
    "    tens = torch.zeros(len(x))\n",
    "    i = 0\n",
    "    for el in x:\n",
    "        tens[i] = float(el)\n",
    "        i+=1\n",
    "    return tens\n",
    "\n",
    "def adjacency_matrix(G):\n",
    "    adj = torch.zeros((len(G.nodes),len(G.nodes)))\n",
    "    for edge in G.edges:\n",
    "        i = edge[0]\n",
    "        j = edge[1]\n",
    "        adj[i,j] = G[i][j][\"weight\"]\n",
    "        adj[j,i] = G[j][i][\"weight\"]\n",
    "    return adj\n",
    "\n",
    "def MaxCut_NN_QAOA(G,x, net):\n",
    "    x = 1-2*x\n",
    "    z = torch.sign(net(x))\n",
    "    adj = adjacency_matrix(G)\n",
    "    return 0.5*torch.matmul(z,torch.mv(adj,z))\n",
    "\n",
    "def cost_function(gamma, beta, net):\n",
    "    counts = {}\n",
    "    result = circuit(gamma, beta)\n",
    "    # In the following line, change 2 --> your number of qubits\n",
    "    for i in range(len(result[0])):\n",
    "        counts[f\"{i:05b}\"] = result[0][i]\n",
    "    E = np.array([])\n",
    "    for bitstring in counts.keys():\n",
    "        x = string_to_tens(bitstring)\n",
    "        E = np.append(E,1*float(MaxCut_NN_QAOA(G, x, net)))\n",
    "        #E += -energy*counts[bitstring]\n",
    "    return sum(E*result[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical noisy circuit\n",
    "This circuit is noisy from the statistical point of view, meaning that it doesn't deliver the exact probability distribution as the previous one, but delivers a given number of samples (defined with `shots`). This circuit will be used for the neural network optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device('default.qubit.tf', wires = len(G.nodes), analytic = False, shots = 500)\n",
    "@qml.qnode(dev, interface = \"tf\")\n",
    "def circuit_stat(gamma, beta, **kwargs):\n",
    "    for i in range(len(G.nodes)):\n",
    "        qml.Hadamard(wires = i)\n",
    "    for j in range(p):\n",
    "        U_C(gamma[j])\n",
    "        U_M(beta[j])\n",
    "    return [qml.sample(qml.PauliZ(i)) for i in range(len(G.nodes))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization\n",
    "\n",
    "Here we introduce some functions to perform the optimization and an example of the optimization employed to obtain our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QAOA_opt(gamma, beta, opt_QAOA, net):\n",
    "    \"\"\"\n",
    "        opt_QAOA --> optimizer used for the QAOA part.\n",
    "                     Must be a tensorflow optimizer\n",
    "        net --> Defines the neural network we employ\n",
    "    \"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        cost = cost_function(gamma, beta, net)\n",
    "    gradients = tape.gradient(cost, [gamma, beta])\n",
    "    opt_QAOA.apply_gradients(zip(gradients, [gamma, beta]))\n",
    "    return gamma, beta, cost\n",
    "\n",
    "def NN_opt(net, gamma, beta, opt_NN):\n",
    "    \"\"\"\n",
    "        net --> Defines the neural network we employ\n",
    "        opt_NN --> Optimizer used for the NN part.\n",
    "                   Must be a torch optimizer\n",
    "    \"\"\"\n",
    "    result = circuit_stat(gamma,beta).numpy()\n",
    "    nodes, shots = np.shape(result)\n",
    "    E = []\n",
    "    opt_NN.zero_grad()\n",
    "    for i in range(shots):\n",
    "        el = [np.float(result[j][i]) for j in range(nodes)]\n",
    "        input = torch.tensor(el)\n",
    "        x = net(input)\n",
    "        E.append(MaxCut_NN(G,x))\n",
    "    cost = sum(E)/shots\n",
    "    cost.backward()\n",
    "    opt_NN.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of optimization\n",
    "\n",
    "net = Net() # Initialize NN\n",
    "opt_QAOA = tf.keras.optimizers.SGD(learning_rate=0.5, momentum = 0.7) # Define the QAOA optimizer\n",
    "opt_NN = optim.SGD(net.parameters(), lr = 0.05) # Define the NN optimizer\n",
    "\n",
    "# Initialize gamma and beta\n",
    "gamma = tf.Variable([4.35], dtype=tf.float64)\n",
    "beta = tf.Variable([0.75], dtype=tf.float64)\n",
    "\n",
    "# Steps\n",
    "steps_QAOA1 = 55 # First QAOA optimization\n",
    "steps_NN = 55 # NN optimization\n",
    "steps_QAOA2 = 55 # Last QAOA optimization\n",
    "\n",
    "print(\"First QAOA optimization\")\n",
    "for k in tqdm(range(steps_QAOA1)):\n",
    "    gamma, beta, cost = QAOA_opt(gamma, beta, opt_QAOA, net)\n",
    "    gamma_init.append(float(gamma))\n",
    "    beta_init.append(float(beta))\n",
    "    en_QAOA.append(cost)\n",
    "\n",
    "print(\"Neural Network optimization\")\n",
    "for k in tqdm(range(steps_NN)):\n",
    "    NN_opt(net, gamma, beta, opt_NN)\n",
    "    en_NN.append(float(checker(gamma,beta,net)))\n",
    "\n",
    "print(\"Second QAOA optimization\")\n",
    "for k in tqdm(range(steps_QAOA2)):\n",
    "    gamma, beta, cost = QAOA_opt(gamma, beta, opt_QAOA2, net)\n",
    "    gamma_after.append(float(gamma))\n",
    "    beta_after.append(float(beta))\n",
    "    en_QAOA.append(cost)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
